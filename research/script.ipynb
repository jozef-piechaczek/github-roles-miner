{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Technical Roles Analysis\n","\n"," ## Script notebook\n","\n"," This notebook contains the script used in our extended study about technical\n"," roles."]},{"cell_type":"markdown","metadata":{},"source":[" ## Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"Python: {platform.python_version()}\")\n","print(f\"Numpy: {np.__version__}\")\n","print(f\"Pandas: {pd.__version__}\")\n","print(f\"Scikit learn: {sklearn.__version__}\")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["SEED = 42\n","FOLDS = 10\n","CORR_THRESHOLD = 0.7\n","REPO_THRESHOLD = 5\n","\n","DEPENDENCIES_PATH = \"/data/repo_dependencies.csv\"\n","DESCRIPTIONS_PATH = \"/data/repo_descriptions.csv\"\n","LANGUAGES_PATH = \"/data/repo_commits.csv\"\n","DEVELOPERS_PATH = \"/data/developers.csv\"\n","DEVELOPERS_FS_PATH = \"/data/developers-with-fullstack.csv\"\n","\n","BIO_MIN = 0.01\n","BIO_MAX = 0.2\n","DESC_MIN = 0.04\n","DESC_MAX = 0.15\n","NAMES_MIN = 0.03\n","NAMES_MAX = 0.25\n","TOPICS_MIN = 0.01\n","TOPICS_MAX = 0.25\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ## Pre-Processing Steps"]},{"cell_type":"markdown","metadata":{},"source":[" ### Author information"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["authors_ds = pd.read_csv(DEVELOPERS_PATH, delimiter=\",\")\n","\n","authors_ds.gh_bio = authors_ds.gh_bio \\\n","    .apply(strip_html_tags) \\\n","    .apply(strip_numbers)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["authors_ds.shape[0]\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filtered_authors = authors_ds[authors_ds.gh_repos >= REPO_THRESHOLD].fillna(\"\")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filtered_authors.loc[:, \"Backend\":].sum()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filtered_authors.drop([\"gh_bio\", \"gh_repos\"], axis=1) \\\n","    .groupby([\"Backend\", \"Frontend\", \"Mobile\", \"DevOps\", \"DataScientist\"]) \\\n","    .count() \\\n","    .reset_index()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bio_bw = apply_bag_of_words(filtered_authors.gh_bio.values.astype(\"U\"),\n","                            BIO_MAX, BIO_MIN)\n","\n","print(f\"{len(bio_bw[0])} words were selected for developer bio after Bag of \"\n","      \"Words.\")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bio_ds = pd.DataFrame(\n","    data=normalize(bio_bw[1].toarray()),\n","    columns=[b + \" (Bio)\" for b in bio_bw[0]],\n","    index=filtered_authors.gh_login\n",")\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ### Repositories descriptions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["descriptions_ds = pd.read_csv(DESCRIPTIONS_PATH, delimiter=\",\")\n","descriptions_ds = descriptions_ds.fillna(\"\")\n","\n","descriptions_ds.repo_desc = descriptions_ds.repo_desc \\\n","    .apply(strip_html_tags) \\\n","    .apply(strip_numbers)\n","descriptions_ds.repo_tags = descriptions_ds.repo_tags \\\n","    .apply(strip_html_tags) \\\n","    .apply(strip_numbers)\n","descriptions_ds.repo_name = descriptions_ds.repo_name \\\n","    .apply(strip_html_tags) \\\n","    .apply(strip_numbers)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["desc_ds = descriptions_ds.groupby(\"gh_login\") \\\n","    .agg(lambda c: \" \".join(c))\n","\n","# right join with bio_ds to include developers without repositories\n","desc_ds = desc_ds \\\n","    .join(bio_ds, how=\"right\") \\\n","    .iloc[:, :3]\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["repo_desc_bw = apply_bag_of_words(\n","    desc_ds.repo_desc.values.astype(\"U\"), DESC_MAX, DESC_MIN)\n","repo_topics_bw = apply_bag_of_words(\n","    desc_ds.repo_tags.values.astype(\"U\"), TOPICS_MAX, TOPICS_MIN)\n","repo_names_bw = apply_bag_of_words(\n","    desc_ds.repo_name.values.astype(\"U\"), NAMES_MAX, NAMES_MIN)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rdesc_ds = pd.DataFrame(\n","    data=normalize(repo_desc_bw[1].toarray()),\n","    columns=[b + \" (desc.)\" for b in repo_desc_bw[0]],\n","    index=desc_ds.index\n",")\n","rtopics_ds = pd.DataFrame(\n","    data=normalize(repo_topics_bw[1].toarray()),\n","    columns=[b + \" (topic)\" for b in repo_topics_bw[0]],\n","    index=desc_ds.index\n",")\n","rnames_ds = pd.DataFrame(\n","    data=normalize(repo_names_bw[1].toarray()),\n","    columns=[b + \" (name)\" for b in repo_names_bw[0]],\n","    index=desc_ds.index\n",")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"{len(repo_desc_bw[0])} words were selected for repository description \"\n","      \"after Bag of Words.\")\n","print(f\"{len(repo_topics_bw[0])} words were selected for repository topics \"\n","      \"after Bag of Words.\")\n","print(f\"{len(repo_names_bw[0])} words were selected for repository names after\"\n","      \" Bag of Words.\")\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ### Languages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lang_ds = pd.read_csv(LANGUAGES_PATH, delimiter=\",\")\n","lang_ds = lang_ds.fillna(0)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lang_rate = lang_ds.loc[:, lang_ds.columns.str.endswith(\"_rate\")] \\\n","    .assign(gh_login=lang_ds.gh_login) \\\n","    .groupby([\"gh_login\"]) \\\n","    .mean()\n","\n","lang_author = lang_ds.loc[:, lang_ds.columns.str.endswith(\"_author\")] \\\n","    .assign(gh_login=lang_ds.gh_login) \\\n","    .groupby([\"gh_login\"]) \\\n","    .sum()\n","\n","lang_total = lang_ds.loc[:, lang_ds.columns.str.endswith(\"_total\")] \\\n","    .assign(gh_login=lang_ds.gh_login) \\\n","    .groupby([\"gh_login\"]) \\\n","    .sum()\n","\n","# right join with bio_ds to include developers without repositories\n","lang_rate = lang_rate.join(bio_ds.iloc[:, :0], how=\"right\").fillna(0)\n","lang_author = lang_author.join(bio_ds.iloc[:, :0], how=\"right\").fillna(0)\n","lang_total = lang_total.join(bio_ds.iloc[:, :0], how=\"right\").fillna(0)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lang_ds = lang_rate.join([lang_author, lang_total])\n","\n","dropped_languages = find_correlation(lang_ds, \"spearman\", CORR_THRESHOLD)\n","lang_ds = lang_ds.drop(dropped_languages.keys(), axis=1)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["unique_languages = lang_ds.nunique()[lang_ds.nunique() <= 1].index\n","lang_ds = lang_ds.drop(unique_languages, axis=1)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lang_ds = lang_ds.rename(columns={\n","    **{k: k.replace(\"_author\", \" (author)\") for k in lang_author.columns},\n","    **{k: k.replace(\"_rate\", \" (rate)\") for k in lang_rate.columns},\n","    **{k: k.replace(\"_total\", \" (total)\") for k in lang_total.columns},\n","})\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ### Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dependencies_ds = pd.read_csv(DEPENDENCIES_PATH, delimiter=\",\")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dependencies_ds = dependencies_ds \\\n","    .drop(\"repo_name\", 1) \\\n","    .groupby(\"gh_login\") \\\n","    .any()\n","\n","# right join with bio_ds to include developers without repositories\n","deps_ds = dependencies_ds \\\n","    .join(bio_ds.iloc[:, :0], how=\"right\") \\\n","    .fillna(False)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dropped_dependencies = find_correlation(deps_ds, \"spearman\", CORR_THRESHOLD)\n","deps_ds = deps_ds.drop(dropped_dependencies.keys(), axis=1)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["unique_dependencies = deps_ds.nunique()[deps_ds.nunique() <= 1].index\n","deps_ds = deps_ds.drop(unique_dependencies, axis=1)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["deps_ds = deps_ds.rename(columns={k: k.replace(\"_dep\", \" (dep.)\")\n","                                  for k in deps_ds.columns})\n",""]},{"cell_type":"markdown","metadata":{},"source":["  ### Finishing up dataset setup"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = bio_ds.join([rdesc_ds, rtopics_ds, rnames_ds, lang_ds, deps_ds])\n","Y = filtered_authors.loc[:, \"Backend\":]\n","\n","Y.index = X.index\n",""]},{"cell_type":"markdown","metadata":{},"source":[" As a result our dataset ends up as:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"Features: {X.shape[0]} rows, {X.shape[1]} columns\")\n","print(f\"Dependent Vars.: {Y.shape[0]} rows, {Y.shape[1]} columns\")\n","\n","print(f\"\\nLanguages: {lang_ds.shape[1]}\")\n","print(f\"Dependencies: {deps_ds.shape[1]}\")\n","print(f\"Description: {rdesc_ds.shape[1]}\")\n","print(f\"Names: {rnames_ds.shape[1]}\")\n","print(f\"Topics: {rtopics_ds.shape[1]}\")\n","print(f\"Short bio: {bio_ds.shape[1]}\")\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ## Classification\n","\n"," For all classifications, we relied on two classification algorithms and a\n"," stratified baseline."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rf = RandomForestClassifier(n_estimators=500, random_state=SEED)\n","baseline = DummyClassifier(\"stratified\", random_state=SEED)\n","nb_baseline = MultinomialNB()\n","skf = KFold(n_splits=FOLDS, random_state=SEED)\n","rf_clf = OneVsRestClassifier(rf)\n","baseline_clf = OneVsRestClassifier(baseline)\n","nb_clf = OneVsRestClassifier(nb_baseline)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ### RQ.1: How accurate are machine learning classifiers in identifying\n"," ### technical roles?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["br_scores, br_folds = classify(X, Y, skf, rf_clf, average=\"micro\")\n","b_scores, b_folds = classify(X, Y, skf, baseline_clf, average=\"micro\")\n","nb_scores, nb_folds = classify(X, Y, skf, nb_clf, average=\"micro\")\n",""]},{"cell_type":"markdown","metadata":{},"source":[" BR Results for identifying developers who **work** in each role:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"******** Random Forest ********\")\n","classify_report(br_scores, Y.columns)\n","print(\"\\n******** Naive Bayes ********\")\n","classify_report(nb_scores, Y.columns)\n","print(\"\\n******** Baseline ********\")\n","classify_report(b_scores, Y.columns)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ### RQ.2: What are the most relevant features to identify technical roles?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["var_imp = feature_importances_rank(X, Y, clone(rf))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["var_imp[\"order\"] = var_imp.groupby(\"role\").rank(\n","    method=\"first\", ascending=False)\n","var_imp[var_imp.category == \"Dependency\"].groupby(\"role\").tail(10)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["top_10_features(var_imp)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" We analyzed the distribution of all features detected as important in\n"," our RandomForest ranking. For this, we plotted the histogram for all 10\n"," features present in feature importance ranking for each role."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for r in Y.columns:\n","    features_df = build_histogram_data(X, Y, var_imp, r)\n","    print(plot_histogram_data(features_df, r))\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ### RQ.3: Do technical roles influence each other during classification?\n","\n"," To answer this question, we applied classifier chain multilabel strategy\n"," over all possible roles configurations."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Y_rq3 = Y.loc[:, :]\n","permutations = itertools.permutations(range(0, Y_rq3.shape[1]))\n","\n","iterations = []\n","for i, p in enumerate(permutations, start=1):\n","    p = list(p)\n","    order = np.array(Y_rq3.columns.tolist())[p]\n","    print(f\"============= {order} =============\")\n","\n","    chain_clf = ClassifierChain(rf, order=list(p), random_state=SEED)\n","    cc_scores, _ = classify(X, Y_rq3, skf, chain_clf, average=\"micro\")\n","    classify_report(cc_scores, Y_rq3)\n","\n","    iteration = {i: r for i, r in enumerate(order)}\n","    iteration.update({\n","        \"index\": i,\n","        \"precision\": cc_scores[\"precision\"],\n","        \"recall\": cc_scores[\"recall\"],\n","        \"f1\": cc_scores[\"f1\"],\n","        \"auc\": cc_scores[\"auc\"],\n","        \"jaccard\": cc_scores[\"jaccard\"],\n","        \"hamming_loss\": cc_scores[\"hamming_loss\"]\n","    })\n","    for role in list(Y_rq3.columns):\n","        iteration.update({\n","            f\"precision_{role}\": cc_scores[f\"precision_{role}\"],\n","            f\"recall_{role}\": cc_scores[f\"recall_{role}\"],\n","            f\"f1_{role}\": cc_scores[f\"f1_{role}\"],\n","        })\n","    iterations.append(iteration)\n","\n","cc_dataset = build_cc_data(iterations, br_scores)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cc_general = cc_dataset[np.any([\n","    cc_dataset.metric == \"Precision\",\n","    cc_dataset.metric == \"Recall\",\n","    cc_dataset.metric == \"F1\",\n","    cc_dataset.metric == \"AUC\",\n","    cc_dataset.metric == \"Jaccard\",\n","    cc_dataset.metric == \"Hamming Loss\"\n","], axis=0)]\n","\n","cc_by_role = cc_dataset[np.any([\n","    cc_dataset.metric.str.contains(\"Backend\"),\n","    cc_dataset.metric.str.contains(\"Frontend\"),\n","    cc_dataset.metric.str.contains(\"Mobile\"),\n","    cc_dataset.metric.str.contains(\"DevOps\"),\n","    cc_dataset.metric.str.contains(\"DataScientist\")\n","], axis=0)]\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\n","    ggplot(cc_general, aes(x=\"index\", y=\"value\"))\n","    + geom_line()\n","    + geom_hline(yintercept=0, linetype=\"dashed\")\n","    + facet_wrap(\"~ metric\", ncol=2)\n","    + labs(x=\"Classifier Chains permutations\", y=\"Metric value\")\n","    + theme_bw()\n",")\n","\n","print(\n","    ggplot(cc_by_role, aes(x=\"index\", y=\"value\"))\n","    + geom_line()\n","    + geom_hline(yintercept=0, linetype=\"dashed\")\n","    + facet_wrap(\"~ metric\", ncol=3)\n","    + labs(x=\"Classifier Chains permutations\", y=\"Metric value\")\n","    + theme_bw()\n",")\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ### RQ.4 How effectively can we identify full-stack developers?\n","\n"," We applied the same labeling process in order to identify FullStack\n"," developers from the developers pool in Stak Overflow, generating a new\n"," dataset with `FullStack` role."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fs_authors_ds = pd.read_csv(DEVELOPERS_FS_PATH, delimiter=\",\")\n","\n","fs_filtered_authors = fs_authors_ds[fs_authors_ds.gh_repos >= REPO_THRESHOLD] \\\n","    .fillna(\"\")\n","fs_filtered_authors.gh_bio = fs_filtered_authors.gh_bio \\\n","    .apply(strip_html_tags) \\\n","    .apply(strip_numbers)\n","\n","fs_bio_bw = apply_bag_of_words(fs_filtered_authors.gh_bio.values.astype(\"U\"),\n","                               BIO_MAX, BIO_MIN)\n","\n","fs_bio_ds = pd.DataFrame(\n","    data=normalize(fs_bio_bw[1].toarray()),\n","    columns=[b + \" (Bio)\" for b in fs_bio_bw[0]],\n","    index=fs_filtered_authors.gh_login\n",")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fs_desc_ds = descriptions_ds.groupby(\"gh_login\") \\\n","    .agg(lambda c: \" \".join(c))\n","\n","fs_desc_ds = fs_desc_ds \\\n","    .join(fs_bio_ds, how=\"right\") \\\n","    .iloc[:, :3]\n","\n","fs_repo_desc_bw = apply_bag_of_words(\n","    fs_desc_ds.repo_desc.values.astype(\"U\"), DESC_MAX, DESC_MIN)\n","fs_repo_topics_bw = apply_bag_of_words(\n","    fs_desc_ds.repo_tags.values.astype(\"U\"), TOPICS_MAX, TOPICS_MIN)\n","fs_repo_names_bw = apply_bag_of_words(\n","    fs_desc_ds.repo_name.values.astype(\"U\"), NAMES_MAX, NAMES_MIN)\n","\n","fs_rdesc_ds = pd.DataFrame(\n","    data=normalize(fs_repo_desc_bw[1].toarray()),\n","    columns=[b + \" (desc.)\" for b in fs_repo_desc_bw[0]],\n","    index=fs_desc_ds.index\n",")\n","fs_rtopics_ds = pd.DataFrame(\n","    data=normalize(fs_repo_topics_bw[1].toarray()),\n","    columns=[b + \" (topic)\" for b in fs_repo_topics_bw[0]],\n","    index=fs_desc_ds.index\n",")\n","fs_rnames_ds = pd.DataFrame(\n","    data=normalize(fs_repo_names_bw[1].toarray()),\n","    columns=[b + \" (name)\" for b in fs_repo_names_bw[0]],\n","    index=fs_desc_ds.index\n",")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fs_lang_rate = lang_rate.join(fs_bio_ds.iloc[:, :0], how=\"right\").fillna(0)\n","fs_lang_author = lang_author.join(fs_bio_ds.iloc[:, :0], how=\"right\").fillna(0)\n","fs_lang_total = lang_total.join(fs_bio_ds.iloc[:, :0], how=\"right\").fillna(0)\n","\n","fs_lang_ds = fs_lang_rate.join([fs_lang_author, fs_lang_total])\n","fs_dropped_languages = find_correlation(fs_lang_ds, \"spearman\", CORR_THRESHOLD)\n","fs_lang_ds = fs_lang_ds.drop(fs_dropped_languages.keys(), axis=1)\n","fs_lang_ds = fs_lang_ds.rename(columns={\n","    **{k: k.replace(\"_author\", \" (author)\") for k in fs_lang_author.columns},\n","    **{k: k.replace(\"_rate\", \" (rate)\") for k in fs_lang_rate.columns},\n","    **{k: k.replace(\"_total\", \" (total)\") for k in fs_lang_total.columns},\n","})\n","\n","fs_lang_unique_cols = fs_lang_ds.nunique()[fs_lang_ds.nunique() <= 1].index\n","fs_lang_ds = fs_lang_ds.drop(fs_lang_unique_cols, axis=1)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fs_deps_ds = dependencies_ds \\\n","    .join(fs_bio_ds.iloc[:, :0], how=\"right\") \\\n","    .fillna(False)\n","\n","fs_dropped_dependencies = find_correlation(\n","    fs_deps_ds, \"spearman\", CORR_THRESHOLD)\n","fs_deps_ds = fs_deps_ds.drop(fs_dropped_dependencies.keys(), axis=1)\n","fs_deps_ds = fs_deps_ds.rename(columns={k: k.replace(\"_dep\", \" (dep.)\")\n","                                        for k in fs_deps_ds.columns})\n","\n","fs_deps_unique_cols = fs_deps_ds.nunique()[fs_deps_ds.nunique() <= 1].index\n","fs_deps_ds = fs_deps_ds.drop(fs_deps_unique_cols, axis=1)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_fs = fs_bio_ds.join(\n","    [fs_rdesc_ds, fs_rtopics_ds, fs_rnames_ds, fs_lang_ds, fs_deps_ds])\n","\n","Y_fs = fs_filtered_authors.loc[:, \"Backend\":]\n","Y_fs.index = X_fs.index\n","\n","print(f\"Features: {X_fs.shape[0]} rows, {X_fs.shape[1]} columns\")\n","print(f\"Dependent Vars.: {Y_fs.shape[0]} rows, {Y_fs.shape[1]} columns\")\n",""]},{"cell_type":"markdown","metadata":{},"source":[" The new `FullStack` developers are distributed as the following:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Y_fs[Y_fs.FullStack == 1] \\\n","    .groupby([\"Backend\", \"Frontend\"]) \\\n","    .count()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fs_br_scores, _ = classify(X_fs, Y_fs, skf, rf_clf, average=\"micro\")\n","fs_b_scores, _ = classify(X_fs, Y_fs, skf, baseline_clf, average=\"micro\")\n","fs_nb_scores, _ = classify(X_fs, Y_fs, skf, nb_clf, average=\"micro\")\n",""]},{"cell_type":"markdown","metadata":{},"source":[" BR Results for identifying developers who **work** in each role, including\n"," `FullStack` role:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"******** Random Forest ********\")\n","classify_report(fs_br_scores, Y_fs.columns)\n","print(\"\\n******** Naive Bayes ********\")\n","classify_report(fs_nb_scores, Y_fs.columns)\n","print(\"\\n******** Baseline ********\")\n","classify_report(fs_b_scores, Y_fs.columns)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" As we can observe, FullStack developers add a lot of noise to the dataset as\n"," the results for both `Backend` and `Frontend` are significantly lower than\n"," before.\n","\n"," This happens because developers who are FullStack do not describe themselves\n"," as Backend and/or Frontend, as these roles are implicit to the FullStack\n"," definition.\n","\n"," Therefore, we decide to redefine the labels of `Backend` and\n"," `Frontend` to 1 whenever a developer is labelled as\n"," `FullStack`:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fs_roles = [\"Backend\", \"Frontend\"]\n","Y_fs.loc[Y_fs.FullStack == 1, fs_roles] = 1\n","\n","fs_br_scores, _ = classify(X_fs, Y_fs, skf, rf_clf, average=\"micro\")\n","fs_b_scores, _ = classify(X_fs, Y_fs, skf, baseline_clf, average=\"micro\")\n","fs_nb_scores, _ = classify(X_fs, Y_fs, skf, nb_clf, average=\"micro\")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"******** Random Forest ********\")\n","classify_report(fs_br_scores, Y_fs.columns)\n","print(\"\\n******** Naive Bayes ********\")\n","classify_report(fs_nb_scores, Y_fs.columns)\n","print(\"\\n******** Baseline ********\")\n","classify_report(fs_b_scores, Y_fs.columns)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" As expected, the results increased significantly after we reassigned both\n"," `Backend` and `Frontend` based on the label values at\n"," `FullStack`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = pd.DataFrame(\n","    cross_val_predict(rf_clf, X, Y, cv=skf),\n","    columns=[\"Backend_pred\", \"Frontend_pred\", \"Mobile_pred\", \"DevOps_pred\",\n","             \"DataScientist_pred\"],\n","    index=Y.index\n",")\n","y_fs_pred = pd.DataFrame(\n","    cross_val_predict(rf_clf, X_fs, Y_fs, cv=skf),\n","    columns=[\"Backend_pred\", \"Frontend_pred\", \"Mobile_pred\", \"DevOps_pred\",\n","             \"DataScientist_pred\", \"FullStack_pred\"],\n","    index=Y_fs.index\n",")\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}